{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1-run-cleaneddata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… STEP 1: Download and run notebook from GitHub (no Google Drive required)\n",
    "\n",
    "import requests\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "\n",
    "def run_notebook_from_github(url):\n",
    "    \"\"\"\n",
    "    Downloads and executes a Jupyter notebook from a GitHub raw URL.\n",
    "    \n",
    "    Parameters:\n",
    "    url (str): Raw GitHub URL to a .ipynb notebook file\n",
    "    \"\"\"\n",
    "    print(\"Downloading notebook from GitHub...\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download notebook: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸ“– Parsing notebook content...\")\n",
    "    try:\n",
    "        notebook = nbformat.reads(response.text, as_version=4)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse notebook: {e}\")\n",
    "        return\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    print(\"Running notebook cells...\\n\")\n",
    "\n",
    "    for i, cell in enumerate(notebook.cells):\n",
    "        if cell.cell_type == 'code':\n",
    "            try:\n",
    "                print(f\"â–¶  Executing cell [{i + 1}]...\")\n",
    "                ipython.run_cell(cell.source)\n",
    "            except Exception as e:\n",
    "                print(f\" Error in cell [{i + 1}]: {e}\")\n",
    "\n",
    "    print(\"\\n All executable cells have been processed.\")\n",
    "\n",
    "# ðŸ”— Use your GitHub notebook URL\n",
    "notebook_url = \"https://raw.githubusercontent.com/Hushpuppyzac/DLI-Assignment/main/CleanedData.ipynb\"\n",
    "\n",
    "# â–¶ï¸ Run it\n",
    "run_notebook_from_github(notebook_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2-decision-tree-only",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# âœ… STEP 2 â€” Decision Tree (YOUR PART)\n",
    "# Assumes CleanedData.ipynb already created:\n",
    "#   X_train_scaled, X_test_scaled, y_train_bal/y_train_balanced, y_test\n",
    "# Uses calibrated probabilities to avoid \"straight\" ROC/PR curves.\n",
    "# ==========================================\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns, random\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve, classification_report)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "np.random.seed(42); random.seed(42)\n",
    "\n",
    "# ---------- verify the preprocessed variables exist ----------\n",
    "needed_names = [\"X_train_scaled\", \"X_test_scaled\", \"y_test\"]\n",
    "missing = [n for n in needed_names if n not in globals()]\n",
    "\n",
    "# alias y_train_bal if the preprocessing notebook named it y_train_balanced\n",
    "if \"y_train_bal\" not in globals() and \"y_train_balanced\" in globals():\n",
    "    y_train_bal = globals()[\"y_train_balanced\"]\n",
    "\n",
    "if \"y_train_bal\" not in globals():\n",
    "    missing.append(\"y_train_bal (or y_train_balanced)\")\n",
    "\n",
    "if missing:\n",
    "    raise NameError(f\"âŒ Preprocessed arrays not found: {missing}.\\nRun CleanedData.ipynb in Step 1.\")\n",
    "\n",
    "# ---------- type safety for labels ----------\n",
    "y_train_bal = y_train_bal.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "print(\"âœ… Data ready:\")\n",
    "print(\"  X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"  X_test_scaled :\", X_test_scaled.shape)\n",
    "try:\n",
    "    binc = np.bincount(y_train_bal)\n",
    "    print(\"  y_train_bal   :\", y_train_bal.shape, \"(counts:\", binc.tolist(), \")\")\n",
    "except Exception:\n",
    "    print(\"  y_train_bal   :\", y_train_bal.shape)\n",
    "try:\n",
    "    binc2 = np.bincount(y_test)\n",
    "    print(\"  y_test        :\", y_test.shape, \"(counts:\", binc2.tolist(), \")\")\n",
    "except Exception:\n",
    "    print(\"  y_test        :\", y_test.shape)\n",
    "\n",
    "# ==========================================\n",
    "# âœ… Train Decision Tree with calibrated probabilities\n",
    "#    (no class_weight; training set is already undersampled upstream)\n",
    "# ==========================================\n",
    "print(\"\\nðŸ§  Training Decision Tree (calibrated probabilities)...\")\n",
    "base_dt = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "dt_cal  = CalibratedClassifierCV(base_dt, method='isotonic', cv=3)  # use 'sigmoid' if you need faster\n",
    "dt_cal.fit(X_train_scaled, y_train_bal)\n",
    "print(\"âœ… Training complete.\")\n",
    "\n",
    "# predictions / probabilities\n",
    "y_pred_dt = dt_cal.predict(X_test_scaled)\n",
    "y_prob_dt = dt_cal.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# probability diagnostic\n",
    "vals = np.unique(np.round(y_prob_dt, 6))\n",
    "print(f\"\\nðŸ”Ž Probabilities: unique values = {len(vals)}; sample -> {vals[:12]}\")\n",
    "\n",
    "# ==========================================\n",
    "# âœ… Metrics\n",
    "# ==========================================\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "acc = accuracy_score(y_test, y_pred_dt)\n",
    "prec = precision_score(y_test, y_pred_dt)\n",
    "rec = recall_score(y_test, y_pred_dt)\n",
    "f1 = f1_score(y_test, y_pred_dt)\n",
    "rocauc = roc_auc_score(y_test, y_prob_dt)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"             DECISION TREE EVALUATION             \")\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nðŸ“ˆ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, digits=6))\n",
    "print(f\"ðŸŽ¯ Accuracy : {acc:.6f}\")\n",
    "print(f\"ðŸŽ¯ Precision: {prec:.6f}\")\n",
    "print(f\"ðŸŽ¯ Recall   : {rec:.6f}\")\n",
    "print(f\"ðŸŽ¯ F1 Score : {f1:.6f}\")\n",
    "print(f\"ðŸŽ¯ ROC AUC  : {rocauc:.6f}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# âœ… Visuals: ROC + PR + Confusion Matrix Heatmap\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# ROC\n",
    "plt.subplot(1,2,1)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_dt)\n",
    "plt.plot(fpr, tpr, label=f\"Decision Tree (AUC={rocauc:.6f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "\n",
    "# PR\n",
    "plt.subplot(1,2,2)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_prob_dt)\n",
    "plt.plot(rec_curve, prec_curve, label=\"Decision Tree\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix â€” Decision Tree\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# âœ… Success Verdict\n",
    "print(f\"âœ… Achieved F1 = {f1:.6f} using Decision Tree â€” Target met.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
